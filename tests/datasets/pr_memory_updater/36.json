{
  "inputs": {
    "repository": "Moonsong-Labs/ai-nexus",
    "pr_num": "36"
  },
  "outputs": {
    "output": "diff --git a/project_memories/global.md b/project_memories/global.md\nindex 53f5313..a999744 100644\n--- a/project_memories/global.md\n+++ b/project_memories/global.md\n@@ -8,26 +8,41 @@\n \n **Key Concepts:**\n 1.  **Multi-Agent System:** The project involves a team of specialized AI agents (Orchestrator, Architect, Coder, Tester, Code Reviewer, Requirement Gatherer, Grumpy, Task Manager) working collaboratively.\n-2.  **Externalized Memory (Semantic Memory):** Agents rely on external storage for persistent knowledge, project state, and context. This addresses context loss in AI agents. The primary mechanism is now `langmem`, providing semantic search capabilities over stored memories, replacing the previous conceptual Markdown-based \"Memory Bank\" and direct `upsert_memory` tool usage for agents based on the template.\n+2.  **Externalized Memory (Semantic Memory & Direct Storage):** Agents rely on external storage for persistent knowledge, project state, and context.\n+    *   **`langmem` Integration:** For agents based on the `agent_template`, `langmem` provides semantic search capabilities over stored memories, managed via the `Agent` class and `SemanticMemory` component.\n+    *   **Direct Store Interaction:** Some agents, like the refactored Orchestrator and Requirement Gatherer, may use custom tools (e.g., `memorize`, `Memory` tool) to directly interact with a `BaseStore` for memory persistence and retrieval (including `asearch` for querying if the store supports it).\n 3.  **LangGraph Framework:** The primary framework used for building the AI agents, defining their state, and managing their execution flow.\n-4.  **Tool-Using Agents:** Agents are equipped with tools to perform actions, interact with systems (like GitHub), and manage their memory (using `langmem` tools or custom tools like `file_dump`).\n+4.  **Tool-Using Agents:** Agents are equipped with tools to perform actions, interact with systems (like GitHub), and manage their memory.\n 5.  **System Prompts:** Detailed system prompts define each agent's role, behavior, constraints, and interaction protocols.\n-6.  **Configuration Management:** Agents have configurable parameters, including LLM models, system prompts, and memory settings (e.g., `use_static_mem`), managed via `Configuration` dataclasses.\n+6.  **Configuration Management:** Agents have configurable parameters, including LLM models and system prompts.\n+    *   **`common.config.Configuration` (NEW):** A base dataclass (`user_id`, `model`, `provider`) for agent configurations, typically extended by specific agent configurations.\n+    *   Agents based on `agent_template` use `Configuration` dataclasses (e.g., `src/agent_template/configuration.py`) which include `use_static_mem`.\n+    *   Refactored agents (e.g., Orchestrator, Requirement Gatherer) define their `Configuration` inline in their `graph.py` files, inheriting from `common.config.Configuration`.\n 7.  **Asynchronous Operations:** The system heavily utilizes `async` and `await` for non-blocking operations within the agent graphs.\n-8.  **`langmem` Integration:** Provides semantic memory capabilities (storage, search) for agents, typically managed via the `Agent` class and `SemanticMemory` component.\n+8.  **`AgentGraph` (NEW - `src/common/graph.py`):** An abstract base class for creating modular, class-based agent graphs. It standardizes graph initialization, compilation, configuration merging, and invocation. Orchestrator and Requirement Gatherer are refactored to use this pattern.\n \n \n-## 2. The Memory Bank System (Shift from Conceptual to `langmem`)\n+## 2. The Memory Bank System (Shift from Conceptual to `langmem` and Direct Store Access)\n \n-The original \"Memory Bank\" concept described a system of structured Markdown files (`memory-bank/`) for agent knowledge persistence, particularly for the \"Cursor\" idea. This concept, detailed in `project_memories/global.md`, served as the initial design principle for externalized memory.\n+The original \"Memory Bank\" concept described a system of structured Markdown files (`memory-bank/`) for agent knowledge persistence. This concept, detailed in `project_memories/global.md`, served as the initial design principle for externalized memory.\n \n-**Current Implementation (`langmem`):** The project has integrated the `langmem` library to provide a more robust and queryable semantic memory system. Agents based on the `agent_template` now utilize `langmem` tools for storing and retrieving memories.\n+**Current Implementation Mechanisms:**\n \n-*   **Storage:** Memories are stored in a `BaseStore` (e.g., `InMemoryStore` configured with embeddings like `GoogleGenerativeAIEmbeddings`).\n-*   **Namespace:** Memories are typically namespaced by `(\"memories\", \"semantic\", user_id)` or `(\"memories\", \"static\", user_id)`.\n-*   **Tools:** Agents use `langmem`-provided tools (`manage_memory`, `search_memory`) for interaction, often wrapped within the `SemanticMemory` component (`src/common/components/memory.py`). A custom `memory_dump` tool is also available.\n-*   **Static Memories:** The concept of static, pre-loaded knowledge persists. JSON files in `.langgraph/static_memories/` can be loaded into the `BaseStore` under a static namespace if `use_static_mem` is enabled in the agent's configuration.\n-*   **Shift:** The shift moves from human-readable Markdown files as the primary memory source to a database/store queried semantically via tools. The core principle of externalized memory remains, but the implementation mechanism has evolved. The specific file structure (`projectbrief.md`, `productContext.md`, etc.) described previously is not directly implemented by the `langmem` system, although the *types* of information they represent might be stored as individual memories.\n+*   **`langmem` for `agent_template`-based agents:**\n+    *   The project has integrated the `langmem` library to provide a robust and queryable semantic memory system for agents derived from `src/agent_template/`.\n+    *   **Storage:** Memories are stored in a `BaseStore` (e.g., `InMemoryStore` configured with embeddings like `GoogleGenerativeAIEmbeddings`).\n+    *   **Namespace:** Memories are typically namespaced by `(\"memories\", \"semantic\", user_id)` or `(\"memories\", \"static\", user_id)`.\n+    *   **Tools:** Agents use `langmem`-provided tools (`manage_memory`, `search_memory`) for interaction, often wrapped within the `SemanticMemory` component (`src/common/components/memory.py`). A custom `memory_dump` tool is also available.\n+    *   **Static Memories:** The concept of static, pre-loaded knowledge persists. JSON files in `.langgraph/static_memories/` can be loaded into the `BaseStore` under a static namespace if `use_static_mem` is enabled in the agent's configuration.\n+    *   **Shift:** For these agents, the shift moves from human-readable Markdown files as the primary memory source to a database/store queried semantically via tools.\n+\n+*   **Direct Store Access for Refactored Agents (e.g., Requirement Gatherer, Orchestrator):**\n+    *   Agents refactored using the `AgentGraph` pattern (like Requirement Gatherer) may implement custom memory tools that interact directly with a `BaseStore` (e.g., using `store.aput` for saving and `store.asearch` for retrieving).\n+    *   For example, the Requirement Gatherer uses a `memorize` tool to save memories like `{\"content\": ..., \"context\": ...}` and `store.asearch` to retrieve them.\n+    *   The Orchestrator uses a `Memory` tool to store information.\n+    *   This approach provides flexibility but differs from the centralized `SemanticMemory` component used by the `agent_template`.\n+\n+The core principle of externalized memory remains, but the implementation mechanism can vary between agents. The specific file structure (`projectbrief.md`, `productContext.md`, etc.) described previously is not directly implemented by these systems, although the *types* of information they represent might be stored as individual memories.\n \n \n ## 3. Project-Level Standards & Goals (`project_memories/PRD.md`)\n@@ -39,7 +54,7 @@ This file outlines the overarching standards and technological choices for the A\n *   **Core Technologies & Frameworks:**\n     *   **Python:** >= 3.12 (Primary programming language).\n     *   **LangGraph:** Core framework for building AI agents.\n-    *   **`langmem`:** >= 0.0.25 (Provides semantic memory capabilities).\n+    *   **`langmem`:** >= 0.0.25 (Provides semantic memory capabilities, primarily for `agent_template` based agents).\n *   **Operation Details:**\n     *   **OS:** Linux/Mac.\n     *   **Provider:** Google Cloud (for deployment).\n@@ -62,21 +77,25 @@ This file outlines the overarching standards and technological choices for the A\n *   **LLM Models:**\n     *   **`gemini-1.5-flash-latest` / `gemini-2.5-flash-preview-04-17` (or similar flash variants):** Preferred for simple tasks, quick evaluations. (`agent_template` default updated to `gemini-2.5-flash-preview-04-17`).\n     *   **`gemini-1.5-pro-latest` (or similar pro variants):** Preferred for complex tasks needing reasoning.\n+    *   **`google_genai:gemini-2.0-flash`:** Default model in `common.config.Configuration`.\n+\n+\n+## 4. General Agent Architecture\n \n+AI Nexus agents are evolving. Two main architectural patterns are emerging:\n \n-## 4. General Agent Architecture (based on `src/agent_template/` and common patterns)\n+**Pattern 1: `agent_template`-based (with `Agent` class and `SemanticMemory`)**\n \n-Most agents in AI Nexus follow a common structural and operational pattern, largely derived from `src/agent_template/`. *Note: Some agents, like the Tester, Coder, or Task Manager, may deviate significantly from this template's graph logic or tool usage.*\n+Most agents in AI Nexus initially followed a common structural and operational pattern, largely derived from `src/agent_template/`. This pattern emphasizes the use of the `Agent` class for LLM interaction and `SemanticMemory` (using `langmem`) for memory management. *Note: Some agents, like the Tester, Coder, or Task Manager, may deviate significantly from this template's graph logic or tool usage.*\n \n-*   **Typical Agent Directory Structure:**\n+*   **Typical Agent Directory Structure (for `agent_template` based):**\n     *   `__init__.py`: Exposes the agent's graph.\n-    *   `agent.py`: **NEW:** Contains the `Agent` class handling LLM interaction and memory integration.\n-    *   `configuration.py`: Defines agent-specific configurable parameters.\n-    *   `graph.py`: Contains the LangGraph `StateGraph` definition, typically using the `Agent` class.\n-    *   `prompts.py`: Stores default system prompts and potentially other prompts.\n+    *   `agent.py`: Contains the `Agent` class handling LLM interaction and `langmem` integration.\n+    *   `configuration.py`: Defines agent-specific configurable parameters (e.g., `model`, `system_prompt`, `use_static_mem`).\n+    *   `graph.py`: Contains the LangGraph `StateGraph` definition, typically using the `Agent` class and `ToolNode`.\n+    *   `prompts.py`: Stores default system prompts.\n     *   `state.py`: Defines the `State` dataclass for the agent's graph.\n-    *   `tools.py`: Defines utility tools (e.g., `file_dump`). Memory tools are now managed by the `Agent` class via `SemanticMemory`.\n-    *   `utils.py`: Utility functions (often moved to `src/common/utils/`).\n+    *   `tools.py`: Defines utility tools (e.g., `file_dump`). Memory tools are managed by the `Agent` class via `SemanticMemory`.\n \n *   **`configuration.py` (Typical Structure - `src/agent_template/configuration.py`):**\n     ```python\n@@ -89,89 +108,116 @@ Most agents in AI Nexus follow a common structural and operational pattern, larg\n \n     @dataclass(kw_only=True)\n     class Configuration:\n-        \"\"\"Main configuration class for the memory graph system.\"\"\"\n-        user_id: str = \"default_user\" # Default user ID\n+        user_id: str = \"default_user\"\n         model: Annotated[str, {\"__template_metadata__\": {\"kind\": \"llm\"}}] = field(\n-            default=\"google_genai:gemini-2.5-flash-preview-04-17\" # Updated default model\n+            default=\"google_genai:gemini-2.5-flash-preview-04-17\"\n         )\n         system_prompt: str = prompts.SYSTEM_PROMPT\n-        use_static_mem: bool = True # NEW: Flag to control static memory loading\n+        use_static_mem: bool = True\n+        # ...\n+    ```\n+\n+*   **`agent.py` (`src/agent_template/agent.py`):**\n+    *   Defines an `Agent` class responsible for LLM interaction and `langmem`-based memory management via `SemanticMemory`.\n+    *   Handles tool binding (memory tools from `SemanticMemory` + utility tools).\n+\n+*   **`graph.py` (Core Logic - `src/agent_template/graph.py`):**\n+    *   Uses the `Agent` class instance for the main model call node.\n+    *   Uses a `ToolNode` for executing tools returned by `agent.get_tools()`.\n+    *   Employs `tools_condition` for routing based on tool calls.\n+\n+**Pattern 2: `AgentGraph`-based (NEW - `src/common/graph.py`)**\n \n-        # Other agent-specific configurations might be added here\n+A newer pattern involves creating agent graphs as classes inheriting from `common.graph.AgentGraph`. This promotes modularity and a standardized way to build, configure, and invoke graphs. Orchestrator and Requirement Gatherer have been refactored to use this pattern.\n \n-        @classmethod\n-        def from_runnable_config(cls, config: RunnableConfig) -> \"Configuration\":\n-            # ... (implementation remains similar)\n-            ...\n+*   **`common/config.py` (NEW):**\n+    ```python\n+    from dataclasses import dataclass\n+\n+    @dataclass(kw_only=True)\n+    class Configuration:\n+        user_id: str = \"default\"\n+        model: str = \"google_genai:gemini-2.0-flash\"\n+        provider: str | None = None\n     ```\n \n-*   **`state.py` (Typical Structure - `src/agent_template/state.py`):**\n+*   **`common/graph.py` (NEW):**\n     ```python\n-    import logging\n-    from dataclasses import dataclass, field\n-    from typing import Annotated, List\n-    from langgraph.graph.message import AnyMessage, add_messages\n+    from abc import ABC, abstractmethod\n+    # ... other imports\n+    from common.config import Configuration\n+\n+    class AgentGraph(ABC):\n+        def __init__(self, config: Configuration, checkpointer=None, store=None): # Simplified\n+            self._config = config\n+            # ...\n+        @abstractmethod\n+        def create_builder(self) -> StateGraph: pass\n+        @property\n+        def compiled_graph(self) -> CompiledStateGraph: # ...\n+        async def ainvoke(self, state: Any, config: RunnableConfig | None = None): # ...\n+    ```\n \n-    logger = logging.getLogger(__name__)\n+*   **Agent-specific `graph.py` (e.g., `src/orchestrator/graph.py`, `src/requirement_gatherer/graph.py`):**\n+    *   Defines an agent-specific `Configuration` dataclass, inheriting from `common.config.Configuration`.\n+    *   Defines an agent-specific graph class, inheriting from `AgentGraph`.\n+    *   Implements `create_builder()` to define the `StateGraph`, nodes, and edges.\n+    *   LLM initialization and tool binding are often handled within the graph class or its nodes directly.\n+    *   Memory interaction might use custom tools defined within the agent's module, interacting with a `BaseStore`.\n \n+*   **`state.py` (Typical Structure - `src/agent_template/state.py`):**\n+    ```python\n+    # ...\n     @dataclass(kw_only=True)\n     class State:\n-        \"\"\"Main graph state.\"\"\"\n         messages: Annotated[List[AnyMessage], add_messages] = field(default_factory=list)\n-        user_id: str = \"default\" # NEW: User ID for memory management\n+        user_id: str = \"default\" # User ID for memory management\n+        # Other agent-specific state fields\n     ```\n \n-*   **`agent.py` (NEW - `src/agent_template/agent.py`):**\n-    *   Defines an `Agent` class responsible for LLM interaction and memory management.\n-    *   `__init__(config: Configuration)`: Initializes the LLM based on `config.model`. Sets up tool dictionary. Initializes `SemanticMemory` if needed. Sets `user_id`.\n-    *   `initialize(config: Configuration)`: Initializes `SemanticMemory` (from `src/common/components/memory.py`) using `agent_name` and `config`. Gets memory tools (`manage_memory`, `search_memory`) and utility tools (`file_dump`). Binds all tools to the LLM.\n-    *   `__call__(state: State, config: RunnableConfig)`: The main method called by the graph node. Ensures the agent is initialized. Ensures `user_id` is present in `config[\"configurable\"]` for `langmem` tools. Constructs messages (including system prompt). Invokes the LLM with messages and tools. Returns updated messages.\n-    *   `get_tools() -> List[Tool]`: Returns all bound tools (memory + utility).\n-\n-*   **`graph.py` (Core Logic - Revised Flow from `src/agent_template/graph.py`):**\n-    *   **`graph_builder(config: Configuration) -> StateGraph`:**\n-        *   Creates a `StateGraph(State)`.\n-        *   Instantiates the `Agent` class: `agent = Agent(config)`.\n-        *   Initializes the agent: `agent.initialize(config)`.\n-        *   Adds the main agent node: `builder.add_node(\"call_model\", agent.__call__)`.\n-        *   Adds a `ToolNode` to execute tool calls: `tool_node = ToolNode(agent.get_tools(), name=\"tools\")`, `builder.add_node(\"tools\", tool_node)`.\n-        *   Sets the entry point: `builder.add_edge(\"__start__\", \"call_model\")`.\n-        *   Adds conditional routing based on tool calls: `builder.add_conditional_edges(\"call_model\", tools_condition)`. `tools_condition` is a LangGraph helper that checks for tool calls in the last message.\n-        *   Routes tool execution back to the model: `builder.add_edge(\"tools\", \"call_model\")`.\n-        *   Routes non-tool responses to the end: `builder.add_edge(\"call_model\", END)`.\n-    *   **Compilation:**\n-        *   A default graph instance is compiled using the builder: `graph = graph_builder(default_config).compile()`.\n-        *   The old logic involving manual memory retrieval (`store.asearch`), formatting memories into the prompt, and the separate `store_memory` node is **removed** and replaced by the `Agent` class logic using `langmem` tools and the `ToolNode`.\n-\n *   **`tools.py` (Utility Tools - `src/agent_template/tools.py`):**\n-    *   **`create_file_dump_tool() -> Tool`:**\n-        *   Defines and returns a `Tool` named `file_dump`.\n-        *   Function signature: `file_dump(content: str, output_path: str, filename: Optional[str] = None) -> bool`.\n-        *   Purpose: Writes arbitrary `content` string to a specified `filename` within the `output_path` directory. Creates the directory if needed. Returns `True` on success, `False` on failure.\n-    *   **`upsert_memory` tool is REMOVED.** Memory operations are handled by `langmem` tools (`manage_memory`, `search_memory`) provided via `SemanticMemory`.\n+    *   `create_file_dump_tool()`: Still relevant for agents needing file output.\n+    *   `upsert_memory` tool is REMOVED from `agent_template`. Memory operations for template-based agents are handled by `langmem` tools. Refactored agents define their own memory tools.\n \n *   **`memory.py` (`src/agent_template/memory.py`):**\n     *   This file has been **DELETED**. Static memory loading logic is now part of `src/common/components/memory.py`.\n \n-*   **`src/common/components/memory.py` (NEW):**\n-    *   **`SemanticMemory` Class:**\n-        *   Encapsulates `langmem` functionality.\n-        *   `__init__(agent_name, store, config)`: Initializes with agent name (for namespacing), an optional `BaseStore`, and configuration.\n-        *   `initialize(config)`: Creates a `BaseStore` (using `create_memory_store`) if not provided. Loads static memories using `load_static_memories` if `config.use_static_mem` is true.\n-        *   `get_tools()`: Returns a list of `langmem` tools (`manage_memory`, `search_memory`) and a custom `memory_dump` tool, configured for the agent's namespace and store.\n-    *   **`load_static_memories(store, user_id)`:** Loads memories from JSON files in `.langgraph/static_memories/` into the provided `store` under the namespace `(\"memories\", \"static\", user_id)`.\n-    *   **`create_memory_tools(namespace, store)`:** Creates the list of memory tools (`manage_memory`, `search_memory`, `memory_dump`). `manage_memory` uses `CategoryMemory` schema (`content`, `category`, `timestamp`). `memory_dump` writes all memories across namespaces to a JSON file.\n-    *   **`create_memory_store()`:** Creates an `InMemoryStore` configured with `GoogleGenerativeAIEmbeddings`.\n-    *   **`CategoryMemory(BaseModel)`:** Pydantic model defining the structure for memories stored via `manage_memory` tool (`content: str`, `category: Literal[\"knowledge\", \"rule\", \"procedure\"]`, `timestamp: str`).\n+*   **`src/common/components/memory.py`:**\n+    *   **`SemanticMemory` Class:** Encapsulates `langmem` functionality for `agent_template`-based agents.\n+    *   **`load_static_memories`:** Loads static memories.\n+    *   **`create_memory_tools`:** Creates `langmem` tools and `memory_dump`.\n+    *   **`create_memory_store`:** Creates `InMemoryStore` with embeddings.\n+    *   **`CategoryMemory`:** Pydantic model for `langmem` memories.\n \n *   **`prompts.py` (`src/agent_template/prompts.py`):**\n-    *   `SYSTEM_PROMPT` updated to instruct the agent to inform the user when memories are retrieved: `\"When using the memory tools for search, always tell the user that those memories were retrieved from my semantic memory store like saying 'I retrieved the following memories from my semantic memory store: {memories}'\"`\n+    *   `SYSTEM_PROMPT` updated to instruct the agent to inform the user when memories are retrieved (relevant for `langmem` search).\n \n \n ## 5. Specific Agent Details\n \n #### 5.1. Orchestrator (`src/orchestrator/`)\n-*   (No changes mentioned in PR - likely still uses its custom `Delegate` and `Memory` tools and stubs, not directly affected by `langmem` integration in the template).\n+*   **Refactored to use `AgentGraph` pattern.**\n+*   **Role:** Orchestrates a team of AI agents. Delegates tasks based on conversation and human input.\n+*   **Structure:**\n+    *   `configuration.py`: **DELETED**.\n+    *   `graph.py`:\n+        *   Defines `Configuration(common.config.Configuration)` including `system_prompt`.\n+        *   Defines `OrchestratorGraph(AgentGraph)`.\n+        *   `create_builder()`: Sets up the graph with an `orchestrate` node and delegation logic.\n+            *   The `orchestrate` node uses an LLM (`model_orchestrator`) bound with `Delegate` and `Memory` tools.\n+            *   `delegate_to` (async) is a conditional edge routing to other agents (actual or stubs) or back to `orchestrate`.\n+        *   Can integrate other `AgentGraph` instances (e.g., `RequirementsGathererGraph`) or stubs.\n+        *   Exports `graph = OrchestratorGraph().compiled_graph`.\n+    *   `prompts.py`:\n+        *   `ORCHESTRATOR_SYSTEM_PROMPT` (loaded from Markdown files) now includes a `{time}` placeholder, formatted with the current system time during prompt assembly.\n+    *   `state.py`: Standard `State` with `messages`.\n+    *   `tools.py`:\n+        *   `Delegate(BaseModel)`: Tool for delegating tasks. **Updated** to require a `content: str` field.\n+        *   `Memory(BaseModel)`: Tool for storing memories, with `origin: str` and `content: str`. (This is likely the `store_memory` tool referred to in prompts).\n+    *   `stubs/__init__.py`:\n+        *   Includes stubs for various agents (Architect, Coder, etc.).\n+        *   **NEW:** `RequirementsGathererStub(AgentGraph)` for stubbing the Requirement Gatherer.\n+    *   `memory/team.md`: Updated to specify that the `Delegate` tool requires the `content` field to be set.\n \n #### 5.2. Architect (`src/architect/`)\n \n@@ -288,14 +334,36 @@ Most agents in AI Nexus follow a common structural and operational pattern, larg\n     *   **Emphasis:** Rigorous analysis, proactive clarification of ambiguities, and strict adherence to defined requirements.\n \n #### 5.6. Requirement Gatherer (`src/requirement_gatherer/`)\n-*   **Role:** Elicits, clarifies, and refines project goals, needs, and constraints.\n-*   **`prompts.py` (`src/requirement_gatherer/prompts.py`):** (Remains the same detailed prompt, including mention of `upsert_memory` which is now superseded by `manage_memory`).\n-*   **Structure:** Based on `agent_template` but with a custom graph.\n-    *   `configuration.py`: Standard. Default model likely updated. Includes `use_static_mem`.\n-    *   `graph.py`: The custom graph flow (`call_model`, `store_memory`, `call_evaluator_model`, `human_feedback`) needs adaptation. The `store_memory` node (which previously handled `upsert_memory` calls) would likely be replaced by a `ToolNode` handling `langmem` tool calls (`manage_memory`) generated by `call_model`. The `call_model` node would now be implemented using the `Agent` class. Memory retrieval logic in `call_evaluator_model` would need to use `langmem` search tools or rely on memories retrieved by `call_model`. *Assumption: This agent now uses the `Agent` class and `langmem` tools.*\n-    *   `state.py`: Standard `State` with `messages` and `user_id`.\n-    *   `tools.py`: Defines utility tools like `file_dump`. `upsert_memory` is removed. Memory tools come from `Agent`.\n-    *   `agent.py`: Contains the `Agent` class instance for this agent.\n+*   **Refactored to use `AgentGraph` pattern.**\n+*   **Role:** Elicits, clarifies, and refines project goals, needs, and constraints by interacting with the user (or a simulated user) and storing gathered information.\n+*   **Structure:**\n+    *   `configuration.py`: **DELETED**.\n+    *   `graph.py`:\n+        *   Defines `Configuration(common.config.Configuration)` including `gatherer_system_prompt`.\n+        *   Defines `RequirementsGathererGraph(AgentGraph)`.\n+        *   **Tools (defined in-file):**\n+            *   `human_feedback(question: str, ...)`: Asks a question to the human (or simulated user) and waits for a response.\n+            *   `memorize(content: str, context: str, ...)`: Stores a piece of information (content and context) into the `BaseStore` using `store.aput((\"memories\", user_id), key, value)`.\n+            *   `summarize(summary: str, ...)`: Tool to indicate the final summary of requirements has been generated.\n+        *   `llm_with_tools`: LLM instance bound with `human_feedback`, `memorize`, and `summarize`.\n+        *   `tool_node = ToolNode(...)` for executing these tools.\n+        *   `create_builder()`:\n+            *   Nodes: `call_model` (invokes `llm_with_tools`), `tool_node`.\n+            *   Flow: `START` -> `call_model`. `call_model` can lead to `tool_node` (if tool call), back to `call_model` (if no tool call and no summary yet), or `END` (if summary is present). `tool_node` leads back to `call_model`.\n+            *   `call_model` node retrieves memories using `store.asearch` to provide context to the LLM.\n+        *   Exports `graph = RequirementsGathererGraph().compiled_graph`.\n+    *   `prompts.py`:\n+        *   `SYSTEM_PROMPT`: **Significantly REVISED**.\n+            *   Instructs the agent to use the `human_feedback` tool for ALL questions to the user.\n+            *   Instructs the agent to use the `memorize` tool (with `content` and `context`) to document information, replacing `upsert_memory`.\n+            *   Instructs the agent to use the `summarize` tool with the final requirements.\n+            *   Details an updated workflow: classification, intelligent questioning (via `human_feedback`), documentation (via `memorize`), risk flagging, progress updates, completion gate, report generation, user confirmation, and final summarization (via `summarize`).\n+        *   `EVALUATOR_SYSTEM_PROMPT`: **REMOVED**.\n+    *   `state.py`:\n+        *   `State` dataclass updated: `veredict` field removed, `summary: str = \"\"` field added.\n+    *   `tools.py`:\n+        *   `upsert_memory` tool still exists but is superseded by the new `memorize` tool (defined in `graph.py`) as per the updated system prompt.\n+        *   `finalize` tool added (async, takes `verdict: str`), but not currently used in the graph defined in `graph.py`.\n \n #### 5.7. Grumpy (`src/grumpy/`)\n *   **Role:** Analyzes and reviews a provided request (task) related to \"designing\" or \"coding\".\n@@ -309,7 +377,7 @@ Most agents in AI Nexus follow a common structural and operational pattern, larg\n \n #### 5.8. Task Manager (`src/task_manager/`) (NEW)\n *   **Role:** Manages tasks, initially focused on identifying necessary input documents for its work (e.g., `prd.md`, `techstack.md`, `split_criteria.md`).\n-*   **Structure:** Appears to follow an older agent structure, not the latest `agent_template` with the `Agent` class and `langmem`.\n+*   **Structure:** Appears to follow an older agent structure, not the latest `agent_template` with the `Agent` class and `langmem`, nor the `AgentGraph` pattern.\n     *   `configuration.py`:\n         *   Defines `TASK_MANAGER_MODEL = \"google_genai:gemini-2.5-flash-preview-04-17\"`.\n         *   Standard `Configuration` dataclass using this model by default.\n@@ -333,117 +401,48 @@ The project uses `pytest` for testing and integrates with LangSmith for evaluati\n     *   `Client()` from `langsmith` for LangSmith interactions.\n     *   `MemorySaver()` from `langgraph.checkpoint.memory` for graph checkpointing.\n     *   `InMemoryStore()` from `langgraph.stores.memory` for agent memory during tests.\n-    *   Graphs are typically compiled with a checkpointer and store: `graph_compiled = graph_builder.compile(checkpointer=memory_saver, store=memory_store)`.\n-    *   A wrapper function (e.g., `run_graph_with_config` or `call_tester_agent`) is often created to:\n-        *   TTake a dataset example (and potentially attachments) as input.\n-        *   Format the input for the graph (e.g., converting to `HumanMessage` lists, injecting attachments as `SystemMessage`s).\n-        *   Generate a unique `thread_id` (using `uuid.uuid4()`) for state isolation in `RunnableConfig`.\n-        *   Set necessary configuration like `user_id` and `model`.\n-        *   Invoke the compiled graph: `await graph_compiled.ainvoke(graph_input, config=config)`.\n-        *   Extract and format the output (often the content of the last message) for evaluation.\n-    *   `client.aevaluate()` is used to run evaluations against LangSmith datasets, passing the wrapper function and dataset name/examples.\n+    *   Graphs are typically compiled with a checkpointer and store. For `AgentGraph` based agents, this is handled within their class or test setup.\n+    *   A wrapper function (e.g., `run_graph_with_config` or `call_tester_agent` or `create_async_graph_caller`) is often created to:\n+        *   Take a dataset example as input.\n+        *   Format the input for the graph.\n+        *   Generate a unique `thread_id`.\n+        *   Set necessary configuration.\n+        *   Invoke the compiled graph (e.g., `await graph.ainvoke(...)`).\n+        *   Extract and format the output.\n+    *   `client.aevaluate()` is used to run evaluations.\n \n *   **`tests/datasets/requirement_gatherer_dataset.py`:**\n     *   Defines `REQUIREMENT_GATHERER_DATASET_NAME = \"Requirement-gatherer-naive-dataset\"`.\n-    *   `create_dataset()` function:\n-        *   Initializes `Client()`.\n-        *   Creates a LangSmith dataset using `client.create_dataset()`.\n-        *   Adds examples (input-output pairs) to the dataset using `client.create_examples()`. Inputs are simple strings, outputs are expected agent responses.\n-\n-*   **`tests/datasets/coder_dataset.py`:**\n-    *   Defines `CODER_DATASET_NAME = \"coder-test-dataset\"`.\n-    *   Defines input (`CodeEvaluatorInputs`) and reference output (`CodeEvaluatorReferenceOutputs`) structures for Coder evaluation.\n-    *   `create_dataset()` function:\n-        *   Initializes `Client()`.\n-        *   Creates the LangSmith dataset.\n-        *   Adds examples (input-output pairs) to the dataset.\n-\n-*   **`tests/datasets/task_manager_dataset.py` (NEW):**\n-    *   Defines `TASK_MANAGER_DATASET_NAME = \"task-manager-requirements\"`.\n-    *   `create_dataset()` function:\n-        *   Initializes `Client()`.\n-        *   Creates a LangSmith dataset.\n-        *   Adds examples to the dataset, focusing on the Task Manager's ability to identify its required input documents (e.g., `prd.md`, `techstack.md`, `split_criteria.md`).\n+    *   `create_dataset()` function for LangSmith dataset creation.\n+\n+*   **`tests/datasets/coder_dataset.py`:** (No changes in PR)\n+*   **`tests/datasets/task_manager_dataset.py`:** (No changes in PR)\n \n *   **`tests/integration_tests/`:**\n-    *   **`test_graph.py`:**\n-        *   `test_memory_storage`: Basic test for the `agent_template` graph's memory storage.\n-        *   Sends a series of messages.\n-        *   Checks if memories are saved in `InMemoryStore` under the correct `user_id` and namespace `(\"memories\", user_id)`.\n-        *   Verifies that memories are not found under an incorrect namespace.\n-    *   **`test_requirement_gatherer.py`:**\n-        *   Tests the requirement gatherer agent against the `REQUIREMENT_GATHERER_DATASET_NAME` LangSmith dataset.\n-        *   Uses `create_async_graph_caller` from `tests.testing` to wrap the agent's graph for evaluation runs.\n-        *   Employs `LLMJudge` from `tests.testing.evaluators`. It calls the `create_correctness_evaluator` method of `LLMJudge` with `plaintext=True` and a custom, detailed prompt (`REQUIREMENT_GATHERER_CORRECTNESS_PROMPT` defined within the test file) to assess the agent's output against reference data.\n-        *   The test invokes `client.aevaluate()` with the graph caller, dataset, the configured evaluator, and an updated `experiment_prefix` (e.g., `\"requirement-gatherer-gemini-2.5-correctness-eval-plain\"`).\n-        *   Uses `print_evaluation` from `testing.formatter` to display evaluation results, with configurable `Verbosity`.\n-        *   The previous complex input formatting logic (formerly in a local `run_graph_with_config` function) has been refactored, likely simplified by the use of `create_async_graph_caller`.\n-    *   **`test_tester_agent.py`:**\n-        *   Tests the tester agent against `LANGSMITH_DATASET_NAME = \"tester-agent-test-dataset\"`.\n-        *   Uses `LLMJudge` from `tests.testing.evaluators` with a custom `CORRECTNESS_PROMPT` (defined in the test file) tailored for evaluating the Tester agent's output (analyzing requirements, asking questions, generating tests).\n-        *   Uses the `create_async_graph_caller` utility from `tests/testing` to wrap the Tester agent's graph for evaluation.\n-        *   Runs the evaluation multiple times (`num_repetitions=3`).\n-    *   **`test_grumpy_agent.py`:**\n-        *   Tests the grumpy agent against a LangSmith dataset (e.g., `LANGSMITH_DATASET_NAME = \"grumpy-failed-questions\"`).\n-        *   Uses `LLMJudge` from `tests.testing.evaluators` to create a `correctness_evaluator` with a specific prompt for judging Grumpy's output.\n-        *   The `create_graph_caller` utility is used to wrap the Grumpy agent's graph for evaluation.\n-    *   **`test_coder.py`:**\n-        *   Contains integration tests for the Coder agent's GitHub interactions using `MockGithubApi`.\n-        *   Tests now instantiate the graph using `coder_new_pr_config().graph_builder(github_tools).compile()`.\n-        *   The custom evaluation framework using `openevals` has been moved to `tests/integration_tests/eval_coder.py`.\n-    *   **`eval_coder.py` (`tests/integration_tests/eval_coder.py`) (NEW):**\n-        *   Defines a custom evaluation framework for the Coder agent (specifically the `coder_new_pr` flow) using `openevals`.\n-        *   `EVAL_PROMPT`: A detailed prompt for an LLM judge to review the Coder agent's trajectory (branch creation, code changes vs. expectations).\n-        *   `Result` TypedDict (`score`, `comment`) for structured LLM judge output.\n-        *   `judge_llm`: An LLM (e.g., `gemini-2.0-flash`) configured for structured output.\n-        *   `evaluate_code_scorer`: Async function that formats inputs and invokes the `judge_llm`.\n-        *   `evaluate_code`: Async function that uses `openevals.utils._arun_evaluator` with `evaluate_code_scorer` to perform evaluation.\n-        *   `invoke_agent(inputs: CodeEvaluatorInputs) -> dict`:\n-            *   Sets up `MockGithubApi` with `inputs[\"starting_code\"]`.\n-            *   Compiles the `coder_new_pr` graph: `coder_new_pr_config().graph_builder(github_tools).compile()`.\n-            *   Invokes the graph with `inputs[\"user_input\"]`.\n-        *   `test_coder_run_eval_dataset()`: Pytest async test that runs `langsmith.aevaluate` using `invoke_agent` against the `CODER_DATASET_NAME`, with `evaluate_code` as the evaluator.\n-    *   **`test_task_manager.py` (NEW):**\n-        *   Tests the Task Manager agent against the `TASK_MANAGER_DATASET_NAME` LangSmith dataset.\n-        *   Compiles the Task Manager graph using `graph_builder.compile(checkpointer=MemorySaver())`.\n-        *   Defines a custom `create_task_manager_graph_caller` function to adapt dataset inputs and invoke the graph.\n-        *   Uses `LLMJudge().create_correctness_evaluator(plaintext=True)` for evaluation.\n-        *   Runs `client.aevaluate()` with `num_repetitions=4`.\n+    *   **`test_graph.py`:** (No changes in PR)\n+    *   **`test_orchestrator.py` (UPDATED):**\n+        *   Now instantiates the graph using `OrchestratorGraph()` instead of `graph_builder.compile()`.\n+    *   **`test_requirement_gatherer.py` (UPDATED):**\n+        *   Tests the requirement gatherer agent against the `REQUIREMENT_GATHERER_DATASET_NAME`.\n+        *   Now instantiates the graph using `RequirementsGathererGraph(checkpointer=memory_saver, store=memory_store)`.\n+        *   Uses `create_async_graph_caller` to wrap the agent's graph for evaluation.\n+        *   Employs `LLMJudge` with a custom prompt for correctness evaluation.\n+    *   **`test_tester_agent.py`:** (No changes in PR)\n+    *   **`test_grumpy_agent.py`:** (No changes in PR)\n+    *   **`test_coder.py`:** (No changes in PR)\n+    *   **`eval_coder.py`:** (No changes in PR)\n+    *   **`test_task_manager.py`:** (No changes in PR)\n \n *   **`tests/testing/__init__.py`:**\n-    *   `get_logger()`: Utility to create a Python logger with a default format.\n-    *   `create_async_graph_caller(graph, process_inputs_fn=None, process_outputs_fn=None)`:\n-        *   A generic async function to create a caller for `graph.ainvoke`.\n-        *   Handles creating a unique `thread_id` for each call.\n-        *   Sets default `user_id` and `model` in the config.\n-        *   Processes input messages (extracting content, wrapping in `HumanMessage`).\n-        *   Returns the content of the last message from the graph's output.\n-\n-*   **`tests/testing/evaluators.py`:**\n-    *   `LLMJudge` class:\n-        *   Wrapper for using an LLM (default: `gemini-1.5-flash-latest`) as an evaluator.\n-        *   `__init__(model_name: str = \"google_genai:gemini-1.5-flash-latest\")`.\n-        *   `create_llm_as_judge(prompt: str, input_keys: List[str], output_key: str, reference_output_key: str, continuous: bool = True)`:\n-            *   Creates an evaluator chain using an LLM.\n-            *   Takes a prompt template, keys for input, output, reference, and a flag for continuous feedback.\n-        *   `create_correctness_evaluator(plaintext: bool, prompt: str)`: (Method usage seen in PRs)\n-            *   A specialized method to create a correctness evaluator, likely taking a prompt and a flag for plaintext comparison.\n-    *   `CORRECTNESS_PROMPT`: A prompt template for an LLM to judge if the `prediction` matches the `reference` output given an `input`.\n-    *   `correctness_evaluator(inputs: dict, outputs: dict, reference_outputs: dict)`:\n-        *   A specific evaluator instance created using `LLMJudge().create_llm_as_judge` (or potentially `LLMJudge().create_correctness_evaluator`) with `CORRECTNESS_PROMPT`.\n-        *   Compares `outputs['output']` (actual agent response) with `reference_outputs['message']['content']` (expected response from dataset).\n-\n-*   **Evaluation Approaches:**\n-    *   **LangSmith Datasets + LLM Judge:** Used for Requirement Gatherer, Tester (simple case), Grumpy, Task Manager. Relies on `client.aevaluate()` and evaluators defined in `tests/testing/evaluators.py`.\n-    *   **Custom `openevals` Framework:** Implemented in `tests/integration_tests/eval_coder.py` for the Coder agent's `coder_new_pr` flow. Involves custom prompts, input/output structures, and direct use of `openevals` utilities with an LLM judge defined within the test file. The test itself (`test_coder_run_eval_dataset`) uses `langsmith.aevaluate` to run these custom evaluations against a dataset.\n-*   **`tests/testing/formatter.py` (Implied by PR usage):**\n-    *   Provides utility functions for formatting and printing evaluation results.\n-    *   Includes `print_evaluation(results, client, verbosity)` for displaying detailed evaluation outcomes.\n-    *   May include enums like `Verbosity` to control output detail.\n-\n-*   **`tests/unit_tests/test_configuration.py`:**\n-    *   `test_configuration_from_none()`: Basic unit test to check if `Configuration.from_runnable_config()` handles a `None` config correctly, falling back to default values.\n+    *   `get_logger()`: Utility for logging.\n+    *   `create_async_graph_caller(graph, ...)`: Generic async function for invoking graphs (can be an `AgentGraph` instance or a compiled graph).\n \n+*   **`tests/testing/evaluators.py`:** (No changes in PR)\n+*   **`tests/testing/formatter.py`:** (No changes in PR)\n+\n+*   **`tests/unit_tests/test_configuration.py` (UPDATED):**\n+    *   The previous test `test_configuration_from_none()` related to `orchestrator.configuration.Configuration` is no longer relevant as that file is deleted.\n+    *   The file now contains a dummy test `test_foo()`.\n \n \n ## 7. Development Workflow & Tools (from `README.md` & `project_memories/PRD.md`)\n@@ -468,9 +467,9 @@ The project uses `pytest` for testing and integrates with LangSmith for evaluati\n     *   `make test-requirement-gatherer`: Runs Requirement Gatherer integration tests.\n     *   `make test-tester`: Runs Tester agent integration tests.\n     *   `make test-architect`: Runs Architect agent integration tests.\n-    *   `make test-task-manager`: Runs Task Manager integration tests (`uv run -- pytest -rs $(INTEGRATION_TEST_FILE)test_task_manager.py`). (NEW)\n+    *   `make test-task-manager`: Runs Task Manager integration tests (`uv run -- pytest -rs $(INTEGRATION_TEST_FILE)test_task_manager.py`).\n     *   `make set-requirement-dataset`: Creates the Requirement Gatherer LangSmith dataset.\n-    *   `make set-task-manager-dataset`: Creates the Task Manager LangSmith dataset (`uv run --env-file .env -- python tests/datasets/task_manager_dataset.py`). (NEW)\n+    *   `make set-task-manager-dataset`: Creates the Task Manager LangSmith dataset (`uv run --env-file .env -- python tests/datasets/task_manager_dataset.py`).\n *   **Configuration:** `.env` file (copied from `.env.example`) for environment variables.\n     *   Required for Google AI services: `GOOGLE_API_KEY` (this is the preferred variable). Alternatively, `GEMINI_API_KEY` can be set; scripts will use `GOOGLE_API_KEY` if present, otherwise they will use `GEMINI_API_KEY`.\n     *   Optional for Coder agent: `GITHUB_APP_ID`, `GITHUB_APP_PRIVATE_KEY`, `GITHUB_REPOSITORY`.\n@@ -488,11 +487,12 @@ The project uses `pytest` for testing and integrates with LangSmith for evaluati\n     *   `langgraph.json` can be used to set the default graph to open in Studio. It now includes entries for the `architect` graph, and **has been updated to reflect the Coder agent's split into `coder_new_pr` and `coder_change_request` graphs.**\n     *   The README provides a badge/link to open the project directly in LangGraph Studio using a GitHub URL.\n *   **Adding New Agents:**\n-    1.  Copy the `src/agent_template/` directory and rename it.\n-    2.  Update package paths within the new agent's files (e.g., imports).\n-    3.  Add the new agent package to `pyproject.toml` under `[tool.poetry.packages]` or `[project.entry-points.\"langgraph.graphs\"]` if using that mechanism for discovery.\n-    4.  Add the new agent graph entry to `langgraph.json`.\n-    5.  Run `make run` and navigate to the new agent in LangGraph Studio.\n+    1.  Copy the `src/agent_template/` directory and rename it (for agents following that pattern).\n+    2.  Alternatively, create a new agent module implementing the `AgentGraph` pattern.\n+    3.  Update package paths within the new agent's files (e.g., imports).\n+    4.  Add the new agent package to `pyproject.toml` under `[tool.poetry.packages]` or `[project.entry-points.\"langgraph.graphs\"]` if using that mechanism for discovery.\n+    5.  Add the new agent graph entry to `langgraph.json`.\n+    6.  Run `make run` and navigate to the new agent in LangGraph Studio.\n *   **Memory Exploration:** LangGraph Studio UI allows reviewing saved memories (e.g., by clicking a \"memory\" button if the store is connected and UI supports it).\n \n \n@@ -505,87 +505,105 @@ ai-nexus/\n \u251c\u2500\u2500 .github/\n \u2502   \u2514\u2500\u2500 workflows/\n \u2502       \u2514\u2500\u2500 checks.yml\n-\u251c\u2500\u2500 Makefile                      # Task runner (Added test-memory-graph, test-task-manager, set-task-manager-dataset targets)\n-\u251c\u2500\u2500 README.md                     # Includes NEW section on using semantic memory\n-\u251c\u2500\u2500 agent_memories/               # Agent-specific static memories (e.g., for Grumpy)\n+\u251c\u2500\u2500 Makefile\n+\u251c\u2500\u2500 README.md\n+\u251c\u2500\u2500 agent_memories/\n \u2502   \u2514\u2500\u2500 grumpy/\n-\u2502       \u251c\u2500\u2500 review-coding.md      # Context for Grumpy's code review\n-\u2502       \u251c\u2500\u2500 review-designing.md   # Context for Grumpy's design review\n-\u2502       \u2514\u2500\u2500 role.md               # Core operational rules and Mermaid diagram for Grumpy\n-\u251c\u2500\u2500 langgraph.json                # LangGraph Studio configuration (UPDATED: Coder agent split into coder_new_pr, coder_change_request)\n-\u251c\u2500\u2500 project_memories/             # Project-wide standards, global context\n-\u2502   \u251c\u2500\u2500 PRD.md                    # Product Requirements Document: standards, tech stack, goals\n-\u2502   \u2514\u2500\u2500 global.md                 # High-level project mission, \"Cursor\" Memory Bank concept\n-\u251c\u2500\u2500 pyproject.toml                # Project metadata, dependencies (for uv/Poetry), package definitions\n-\u251c\u2500\u2500 src/                          # Source code for all agents and common utilities\n-\u2502   \u251c\u2500\u2500 agent_template/           # Base template for creating new agents\n+\u2502       \u251c\u2500\u2500 review-coding.md\n+\u2502       \u251c\u2500\u2500 review-designing.md\n+\u2502       \u2514\u2500\u2500 role.md\n+\u251c\u2500\u2500 langgraph.json\n+\u251c\u2500\u2500 project_memories/\n+\u2502   \u251c\u2500\u2500 PRD.md\n+\u2502   \u2514\u2500\u2500 global.md\n+\u251c\u2500\u2500 pyproject.toml                # UPDATED: Ruff per-file ignores\n+\u251c\u2500\u2500 src/\n+\u2502   \u251c\u2500\u2500 agent_template/\n \u2502   \u2502   \u251c\u2500\u2500 __init__.py\n-\u2502   \u2502   \u251c\u2500\u2500 agent.py              # NEW: Agent class handling LLM/memory interaction\n-\u2502   \u2502   \u251c\u2500\u2500 configuration.py      # UPDATED: Added use_static_mem, new default model\n-\u2502   \u2502   \u251c\u2500\u2500 graph.py              # REVISED: Uses Agent class, ToolNode, tools_condition\n+\u2502   \u2502   \u251c\u2500\u2500 agent.py\n+\u2502   \u2502   \u251c\u2500\u2500 configuration.py\n+\u2502   \u2502   \u251c\u2500\u2500 graph.py\n \u2502   \u2502   \u251c\u2500\u2500 memory.py             # DELETED\n-\u2502   \u2502   \u251c\u2500\u2500 prompts.py            # UPDATED: Instructs agent to mention memory retrieval\n-\u2502   \u2502   \u251c\u2500\u2500 state.py              # UPDATED: Added user_id field\n-\u2502   \u2502   \u251c\u2500\u2500 tools.py              # REVISED: Defines file_dump tool, upsert_memory removed\n-\u2502   \u2502   \u2514\u2500\u2500 utils.py              # (May be moved/refactored to common)\n-\u2502   \u251c\u2500\u2500 architect/                # Architect agent: manages project design and documentation\n-\u2502   \u2502   \u251c\u2500\u2500 output.py             # Pydantic models for Architect's structured output\n-\u2502   \u2502   \u2514\u2500\u2500 prompts/v0.1.md       # Detailed system prompt for Architect (v0.1)\n-\u2502   \u251c\u2500\u2500 code_reviewer/            # Code Reviewer agent: reviews code for quality\n-\u2502   \u2502   \u2514\u2500\u2500 system_prompt.md      # System prompt for Code Reviewer\n-\u2502   \u251c\u2500\u2500 coder/                    # Coder agent: writes code, interacts with GitHub (Now split into new_pr and change_request flows)\n-\u2502   \u2502   \u251c\u2500\u2500 __init__.py           # Exports graph_new_pr, graph_change_request\n-\u2502   \u2502   \u251c\u2500\u2500 graph.py              # Defines CoderInstanceConfig, _graph_builder, and config factories for new_pr and change_request flows\n-\u2502   \u2502   \u251c\u2500\u2500 lg_server.py          # NEW: Exposes compiled Coder graphs (graph_new_pr, graph_change_request) for LangGraph Server, handles dynamic GitHub source\n-\u2502   \u2502   \u251c\u2500\u2500 mocks.py              # Mock GitHub API for testing (UPDATED: new mock methods for PR details)\n-\u2502   \u2502   \u251c\u2500\u2500 prompts.py            # UPDATED: NEW_PR_SYSTEM_PROMPT, CHANGE_REQUEST_SYSTEM_PROMPT\n-\u2502   \u2502   \u251c\u2500\u2500 state.py              # Defines Coder agent state\n-\u2502   \u2502   \u251c\u2500\u2500 tools.py              # Defines GitHub tools (UPDATED: new tools for PR details, GITHUB_TOOLS list, get_github_tools function)\n-\u2502   \u2502   \u2514\u2500\u2500 README.md             # Setup instructions for GitHub App\n-\u2502   \u251c\u2500\u2500 common/                   # Common utilities shared across agents\n-\u2502   \u2502   \u2514\u2500\u2500 utils/                # Shared utility functions\n-\u2502   \u251c\u2500\u2500 grumpy/                   # Grumpy agent: reviews design/coding tasks based on strict rules\n-\u2502   \u251c\u2500\u2500 orchestrator/             # Orchestrator agent: delegates tasks to other agents\n+\u2502   \u2502   \u251c\u2500\u2500 prompts.py\n+\u2502   \u2502   \u251c\u2500\u2500 state.py\n+\u2502   \u2502   \u251c\u2500\u2500 tools.py\n+\u2502   \u2502   \u2514\u2500\u2500 utils.py\n+\u2502   \u251c\u2500\u2500 architect/\n+\u2502   \u2502   \u251c\u2500\u2500 output.py\n+\u2502   \u2502   \u2514\u2500\u2500 prompts/v0.1.md\n+\u2502   \u251c\u2500\u2500 code_reviewer/\n+\u2502   \u2502   \u2514\u2500\u2500 system_prompt.md\n+\u2502   \u251c\u2500\u2500 coder/\n+\u2502   \u2502   \u251c\u2500\u2500 __init__.py\n+\u2502   \u2502   \u251c\u2500\u2500 graph.py\n+\u2502   \u2502   \u251c\u2500\u2500 lg_server.py\n+\u2502   \u2502   \u251c\u2500\u2500 mocks.py\n+\u2502   \u2502   \u251c\u2500\u2500 prompts.py\n+\u2502   \u2502   \u251c\u2500\u2500 state.py\n+\u2502   \u2502   \u251c\u2500\u2500 tools.py\n+\u2502   \u2502   \u2514\u2500\u2500 README.md\n+\u2502   \u251c\u2500\u2500 common/\n+\u2502   \u2502   \u251c\u2500\u2500 config.py             # NEW: Base Configuration dataclass\n+\u2502   \u2502   \u251c\u2500\u2500 graph.py              # NEW: AgentGraph abstract base class\n+\u2502   \u2502   \u2514\u2500\u2500 utils/\n+\u2502   \u251c\u2500\u2500 grumpy/\n+\u2502   \u251c\u2500\u2500 orchestrator/\n+\u2502   \u2502   \u251c\u2500\u2500 __init__.py\n+\u2502   \u2502   \u251c\u2500\u2500 configuration.py      # DELETED\n+\u2502   \u2502   \u251c\u2500\u2500 graph.py              # REVISED: Uses AgentGraph, inline Configuration, new logic\n \u2502   \u2502   \u251c\u2500\u2500 memory/               # Markdown files defining Orchestrator's rules and team\n-\u2502   \u2502   \u2514\u2500\u2500 stubs/                # Stub implementations for delegated agent calls (for testing/dev)\n-\u2502   \u251c\u2500\u2500 requirement_gatherer/     # Requirement Gatherer agent: elicits and clarifies requirements\n-\u2502   \u251c\u2500\u2500 task_manager/             # Task Manager agent (NEW - uses older agent structure)\n-\u2502   \u2502   \u251c\u2500\u2500 __init__.py           # (Implied)\n-\u2502   \u2502   \u251c\u2500\u2500 configuration.py      # Defines specific model, standard config\n-\u2502   \u2502   \u251c\u2500\u2500 graph.py              # Uses older graph structure (call_model, store_memory, etc.)\n-\u2502   \u2502   \u251c\u2500\u2500 prompts.py            # (Implied)\n-\u2502   \u2502   \u251c\u2500\u2500 state.py              # (Implied)\n-\u2502   \u2502   \u2514\u2500\u2500 tools.py              # (Implied, likely with upsert_memory)\n-\u2502   \u2514\u2500\u2500 tester/                   # Tester agent: generates tests based on requirements\n-\u2502       \u251c\u2500\u2500 README.md             # Goal, responsibilities, workflow diagram for Tester\n-\u2502       \u251c\u2500\u2500 configuration.py      # Default model changed to gemini-2.0-flash-lite\n-\u2502       \u251c\u2500\u2500 graph.py              # REVISED: Uses structured output, multi-stage workflow (analyze/generate), no memory store interaction\n-\u2502       \u251c\u2500\u2500 output.py             # Pydantic models for Tester's structured output\n-\u2502       \u251c\u2500\u2500 state.py              # Standard state (messages)\n-\u2502       \u251c\u2500\u2500 test-agent-system-prompt.md # REVISED: System prompt made more succinct, assertive, with clearer guidelines on asking questions, and new workflow/rule sections.\n-\u2502       \u251c\u2500\u2500 test-prompts/         # Example requirements for Tester\n-\u2502       \u2502   \u251c\u2500\u2500 web-api-simple.md # NEW: Simpler web API example\n+\u2502   \u2502   \u2502   \u2514\u2500\u2500 team.md           # UPDATED: Delegate tool content requirement\n+\u2502   \u2502   \u251c\u2500\u2500 prompts.py            # UPDATED: System prompt includes {time}\n+\u2502   \u2502   \u251c\u2500\u2500 state.py\n+\u2502   \u2502   \u251c\u2500\u2500 stubs/                # Stub implementations\n+\u2502   \u2502   \u2502   \u2514\u2500\u2500 __init__.py       # UPDATED: RequirementsGathererStub added\n+\u2502   \u2502   \u251c\u2500\u2500 test.py               # NEW: Local test script for orchestrator\n+\u2502   \u2502   \u2514\u2500\u2500 tools.py              # UPDATED: Delegate tool requires 'content' field\n+\u2502   \u251c\u2500\u2500 requirement_gatherer/\n+\u2502   \u2502   \u251c\u2500\u2500 __init__.py\n+\u2502   \u2502   \u251c\u2500\u2500 configuration.py      # DELETED\n+\u2502   \u2502   \u251c\u2500\u2500 graph.py              # REVISED: Uses AgentGraph, inline Configuration, new tools (human_feedback, memorize, summarize), new flow\n+\u2502   \u2502   \u251c\u2500\u2500 prompts.py            # REVISED: Major overhaul of SYSTEM_PROMPT, new tools, new workflow. EVALUATOR_SYSTEM_PROMPT removed.\n+\u2502   \u2502   \u251c\u2500\u2500 state.py              # REVISED: 'veredict' removed, 'summary' added\n+\u2502   \u2502   \u2514\u2500\u2500 tools.py              # 'upsert_memory' still present, new 'finalize' tool (unused by graph.py). 'memorize' tool is in graph.py.\n+\u2502   \u251c\u2500\u2500 task_manager/\n+\u2502   \u2502   \u251c\u2500\u2500 __init__.py\n+\u2502   \u2502   \u251c\u2500\u2500 configuration.py\n+\u2502   \u2502   \u251c\u2500\u2500 graph.py\n+\u2502   \u2502   \u251c\u2500\u2500 prompts.py\n+\u2502   \u2502   \u251c\u2500\u2500 state.py\n+\u2502   \u2502   \u2514\u2500\u2500 tools.py\n+\u2502   \u2514\u2500\u2500 tester/\n+\u2502       \u251c\u2500\u2500 README.md\n+\u2502       \u251c\u2500\u2500 configuration.py\n+\u2502       \u251c\u2500\u2500 graph.py\n+\u2502       \u251c\u2500\u2500 output.py\n+\u2502       \u251c\u2500\u2500 state.py\n+\u2502       \u251c\u2500\u2500 test-agent-system-prompt.md\n+\u2502       \u251c\u2500\u2500 test-prompts/\n+\u2502       \u2502   \u251c\u2500\u2500 web-api-simple.md\n \u2502       \u2502   \u2514\u2500\u2500 web-api.md\n-\u2502       \u251c\u2500\u2500 tools.py              # Defines upsert_memory, but NOT used by current graph.py\n-\u2502       \u2514\u2500\u2500 utils.py              # Standard utils\n-\u2514\u2500\u2500 tests/                        # Automated tests\n-    \u251c\u2500\u2500 datasets/                 # Scripts for creating LangSmith datasets\n-    \u2502   \u251c\u2500\u2500 coder_dataset.py      # Defines LangSmith dataset for Coder agent evaluation\n+\u2502       \u251c\u2500\u2500 tools.py\n+\u2502       \u2514\u2500\u2500 utils.py\n+\u2514\u2500\u2500 tests/\n+    \u251c\u2500\u2500 datasets/\n+    \u2502   \u251c\u2500\u2500 coder_dataset.py\n     \u2502   \u251c\u2500\u2500 requirement_gatherer_dataset.py\n-    \u2502   \u2514\u2500\u2500 task_manager_dataset.py # Defines LangSmith dataset for Task Manager agent\n-    \u251c\u2500\u2500 integration_tests/        # Integration tests for agents and full graph functionality\n-    \u2502   \u251c\u2500\u2500 test_architect_agent.py # Tests for Architect agent\n-    \u2502   \u251c\u2500\u2500 test_coder.py         # REVISED: Basic integration tests for Coder, uses coder_new_pr_config. Advanced eval moved.\n-    \u2502   \u251c\u2500\u2500 eval_coder.py         # NEW: Custom evaluation framework for Coder agent (coder_new_pr flow) using openevals and LangSmith.\n-    \u2502   \u251c\u2500\u2500 test_graph.py         # Tests agent_template memory\n+    \u2502   \u2514\u2500\u2500 task_manager_dataset.py\n+    \u251c\u2500\u2500 integration_tests/\n+    \u2502   \u251c\u2500\u2500 test_architect_agent.py\n+    \u2502   \u251c\u2500\u2500 test_coder.py\n+    \u2502   \u251c\u2500\u2500 eval_coder.py\n+    \u2502   \u251c\u2500\u2500 test_graph.py\n     \u2502   \u251c\u2500\u2500 test_grumpy_agent.py\n-    \u2502   \u251c\u2500\u2500 test_requirement_gatherer.py\n-    \u2502   \u251c\u2500\u2500 test_task_manager.py  # Tests for Task Manager agent\n-    \u2502   \u2514\u2500\u2500 test_tester_agent.py  # Uses create_async_graph_caller, LLMJudge, custom prompt, specific dataset\n-    \u251c\u2500\u2500 testing/                  # Test utilities,\n-    \u2502   \u251c\u2500\u2500 __init__.py           # REVISED: create_async_graph_caller updated\n-    \u2502   \u251c\u2500\u2500 evaluators.py         # LLM-based evaluators (e.g., LLMJudge)\n-    \u2502   \u2514\u2500\u2500 formatter.py          # Utilities for formatting/printing evaluation results\n-    \u2514\u2500\u2500 unit_tests/               # Unit tests for isolated components\n-        \u2514\u2500\u2500 test_configuration.py\n+    \u2502   \u251c\u2500\u2500 test_orchestrator.py    # UPDATED: Uses OrchestratorGraph\n+    \u2502   \u251c\u2500\u2500 test_requirement_gatherer.py # UPDATED: Uses RequirementsGathererGraph\n+    \u2502   \u251c\u2500\u2500 test_task_manager.py\n+    \u2502   \u2514\u2500\u2500 test_tester_agent.py\n+    \u251c\u2500\u2500 testing/\n+    \u2502   \u251c\u2500\u2500 __init__.py\n+    \u2502   \u251c\u2500\u2500 evaluators.py\n+    \u2502   \u2514\u2500\u2500 formatter.py\n+    \u2514\u2500\u2500 unit_tests/\n+        \u2514\u2500\u2500 test_configuration.py   # UPDATED: Now a dummy test\n ```"
  }
}